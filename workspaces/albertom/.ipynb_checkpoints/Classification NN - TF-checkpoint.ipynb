{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 - Import packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "from matplotlib import collections  as mc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 5.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Load data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 - Train set: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19423, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-18.341700</td>\n",
       "      <td>-1.499321</td>\n",
       "      <td>-1.355711</td>\n",
       "      <td>4.085164</td>\n",
       "      <td>0.507722</td>\n",
       "      <td>1.323943</td>\n",
       "      <td>-1.158738</td>\n",
       "      <td>3.239028</td>\n",
       "      <td>-0.351744</td>\n",
       "      <td>4.684859</td>\n",
       "      <td>-1.288307</td>\n",
       "      <td>-0.614557</td>\n",
       "      <td>-1.519203</td>\n",
       "      <td>1.271893</td>\n",
       "      <td>0.056804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.524442</td>\n",
       "      <td>-2.030392</td>\n",
       "      <td>-0.674545</td>\n",
       "      <td>-3.829560</td>\n",
       "      <td>0.021374</td>\n",
       "      <td>-3.275420</td>\n",
       "      <td>1.350335</td>\n",
       "      <td>1.898675</td>\n",
       "      <td>0.694699</td>\n",
       "      <td>-2.756291</td>\n",
       "      <td>-0.794836</td>\n",
       "      <td>1.239952</td>\n",
       "      <td>1.987590</td>\n",
       "      <td>1.351630</td>\n",
       "      <td>0.320299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.877070</td>\n",
       "      <td>-5.641901</td>\n",
       "      <td>3.048596</td>\n",
       "      <td>1.115479</td>\n",
       "      <td>0.016561</td>\n",
       "      <td>0.644258</td>\n",
       "      <td>-0.395762</td>\n",
       "      <td>0.024898</td>\n",
       "      <td>0.223658</td>\n",
       "      <td>0.744945</td>\n",
       "      <td>0.004955</td>\n",
       "      <td>-0.120828</td>\n",
       "      <td>-0.338187</td>\n",
       "      <td>0.931008</td>\n",
       "      <td>0.728083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-5.824436</td>\n",
       "      <td>-7.146028</td>\n",
       "      <td>2.308765</td>\n",
       "      <td>1.485002</td>\n",
       "      <td>1.753751</td>\n",
       "      <td>0.034794</td>\n",
       "      <td>0.535366</td>\n",
       "      <td>-0.180122</td>\n",
       "      <td>1.468998</td>\n",
       "      <td>2.604550</td>\n",
       "      <td>0.730246</td>\n",
       "      <td>-0.127975</td>\n",
       "      <td>0.202254</td>\n",
       "      <td>0.150643</td>\n",
       "      <td>0.239629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.021571</td>\n",
       "      <td>4.583527</td>\n",
       "      <td>-3.234845</td>\n",
       "      <td>2.983661</td>\n",
       "      <td>-2.991689</td>\n",
       "      <td>-1.813864</td>\n",
       "      <td>1.493669</td>\n",
       "      <td>-2.691452</td>\n",
       "      <td>-2.037845</td>\n",
       "      <td>2.800191</td>\n",
       "      <td>-1.108040</td>\n",
       "      <td>0.335971</td>\n",
       "      <td>-0.956513</td>\n",
       "      <td>0.223005</td>\n",
       "      <td>0.470329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6  \\\n",
       "0 -18.341700 -1.499321 -1.355711  4.085164  0.507722  1.323943 -1.158738   \n",
       "1  19.524442 -2.030392 -0.674545 -3.829560  0.021374 -3.275420  1.350335   \n",
       "2   0.877070 -5.641901  3.048596  1.115479  0.016561  0.644258 -0.395762   \n",
       "3  -5.824436 -7.146028  2.308765  1.485002  1.753751  0.034794  0.535366   \n",
       "4  -5.021571  4.583527 -3.234845  2.983661 -2.991689 -1.813864  1.493669   \n",
       "\n",
       "          7         8         9        10        11        12        13  \\\n",
       "0  3.239028 -0.351744  4.684859 -1.288307 -0.614557 -1.519203  1.271893   \n",
       "1  1.898675  0.694699 -2.756291 -0.794836  1.239952  1.987590  1.351630   \n",
       "2  0.024898  0.223658  0.744945  0.004955 -0.120828 -0.338187  0.931008   \n",
       "3 -0.180122  1.468998  2.604550  0.730246 -0.127975  0.202254  0.150643   \n",
       "4 -2.691452 -2.037845  2.800191 -1.108040  0.335971 -0.956513  0.223005   \n",
       "\n",
       "         14  \n",
       "0  0.056804  \n",
       "1  0.320299  \n",
       "2  0.728083  \n",
       "3  0.239629  \n",
       "4  0.470329  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_1 = pd.read_csv(\"../common/albertom/train_test_val_split/X_train_pca.csv\", index_col=\"Unnamed: 0\")\n",
    "# df_data_1 = df_data_1.head(500)\n",
    "print(df_data_1.shape)\n",
    "df_data_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 - Train labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19423, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>18329863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>51718313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>32674991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>46137138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>15314372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0         1\n",
       "0  0  18329863\n",
       "1  1  51718313\n",
       "2  1  32674991\n",
       "3  1  46137138\n",
       "4  0  15314372"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target_data_1 = pd.read_csv(\"../common/albertom/train_test_val_split/y_train.csv\", index_col=\"Unnamed: 0\")\n",
    "# df_target_data_1 = df_target_data_1.head(500)\n",
    "print(df_target_data_1.shape)\n",
    "df_target_data_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 - Test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4033, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.718190</td>\n",
       "      <td>-6.316477</td>\n",
       "      <td>-2.083559</td>\n",
       "      <td>0.975329</td>\n",
       "      <td>-0.296123</td>\n",
       "      <td>1.974713</td>\n",
       "      <td>0.379124</td>\n",
       "      <td>-0.007346</td>\n",
       "      <td>1.958610</td>\n",
       "      <td>-1.165543</td>\n",
       "      <td>0.759262</td>\n",
       "      <td>-0.382965</td>\n",
       "      <td>-0.584148</td>\n",
       "      <td>1.553133</td>\n",
       "      <td>0.568045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.020365</td>\n",
       "      <td>-0.602705</td>\n",
       "      <td>9.139554</td>\n",
       "      <td>0.840974</td>\n",
       "      <td>0.546386</td>\n",
       "      <td>-5.230693</td>\n",
       "      <td>-0.084946</td>\n",
       "      <td>-10.231455</td>\n",
       "      <td>-0.852961</td>\n",
       "      <td>0.451180</td>\n",
       "      <td>0.669972</td>\n",
       "      <td>-0.829123</td>\n",
       "      <td>1.024230</td>\n",
       "      <td>0.229725</td>\n",
       "      <td>0.039168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.975737</td>\n",
       "      <td>-3.348945</td>\n",
       "      <td>-0.572407</td>\n",
       "      <td>0.087099</td>\n",
       "      <td>0.788437</td>\n",
       "      <td>0.297061</td>\n",
       "      <td>0.889188</td>\n",
       "      <td>0.581228</td>\n",
       "      <td>-0.122152</td>\n",
       "      <td>-0.471265</td>\n",
       "      <td>0.488114</td>\n",
       "      <td>-0.081485</td>\n",
       "      <td>-0.172004</td>\n",
       "      <td>-0.577762</td>\n",
       "      <td>-0.305729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-22.105474</td>\n",
       "      <td>0.258111</td>\n",
       "      <td>0.720882</td>\n",
       "      <td>-3.436382</td>\n",
       "      <td>-1.524025</td>\n",
       "      <td>0.087214</td>\n",
       "      <td>-0.444141</td>\n",
       "      <td>0.608868</td>\n",
       "      <td>1.049485</td>\n",
       "      <td>0.409755</td>\n",
       "      <td>-0.329483</td>\n",
       "      <td>-0.048181</td>\n",
       "      <td>-0.009138</td>\n",
       "      <td>-0.527190</td>\n",
       "      <td>1.436177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-14.011642</td>\n",
       "      <td>2.771666</td>\n",
       "      <td>-3.670775</td>\n",
       "      <td>-0.453639</td>\n",
       "      <td>-0.303950</td>\n",
       "      <td>-1.095188</td>\n",
       "      <td>-2.580395</td>\n",
       "      <td>-1.656323</td>\n",
       "      <td>-1.115220</td>\n",
       "      <td>0.806741</td>\n",
       "      <td>-0.176124</td>\n",
       "      <td>0.275890</td>\n",
       "      <td>-0.784060</td>\n",
       "      <td>1.083728</td>\n",
       "      <td>-1.022576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6  \\\n",
       "0  -1.718190 -6.316477 -2.083559  0.975329 -0.296123  1.974713  0.379124   \n",
       "1   0.020365 -0.602705  9.139554  0.840974  0.546386 -5.230693 -0.084946   \n",
       "2   9.975737 -3.348945 -0.572407  0.087099  0.788437  0.297061  0.889188   \n",
       "3 -22.105474  0.258111  0.720882 -3.436382 -1.524025  0.087214 -0.444141   \n",
       "4 -14.011642  2.771666 -3.670775 -0.453639 -0.303950 -1.095188 -2.580395   \n",
       "\n",
       "           7         8         9        10        11        12        13  \\\n",
       "0  -0.007346  1.958610 -1.165543  0.759262 -0.382965 -0.584148  1.553133   \n",
       "1 -10.231455 -0.852961  0.451180  0.669972 -0.829123  1.024230  0.229725   \n",
       "2   0.581228 -0.122152 -0.471265  0.488114 -0.081485 -0.172004 -0.577762   \n",
       "3   0.608868  1.049485  0.409755 -0.329483 -0.048181 -0.009138 -0.527190   \n",
       "4  -1.656323 -1.115220  0.806741 -0.176124  0.275890 -0.784060  1.083728   \n",
       "\n",
       "         14  \n",
       "0  0.568045  \n",
       "1  0.039168  \n",
       "2 -0.305729  \n",
       "3  1.436177  \n",
       "4 -1.022576  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_2 = pd.read_csv(\"../common/albertom/train_test_val_split/X_test_pca.csv\", index_col=\"Unnamed: 0\")\n",
    "# df_data_2 = df_data_2.head(100)\n",
    "print(df_data_2.shape)\n",
    "df_data_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 - Test labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4033, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10930294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>55016784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>48129536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>37805023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>22798417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0         1\n",
       "0  1  10930294\n",
       "1  1  55016784\n",
       "2  0  48129536\n",
       "3  1  37805023\n",
       "4  0  22798417"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target_data_2 = pd.read_csv(\"../common/albertom/train_test_val_split/y_test.csv\", index_col=\"Unnamed: 0\")\n",
    "# df_target_data_2 = df_target_data_2.head(100)\n",
    "print(df_target_data_2.shape)\n",
    "df_target_data_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 - Val set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3428, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.121868</td>\n",
       "      <td>-4.745601</td>\n",
       "      <td>-3.924026</td>\n",
       "      <td>2.321226</td>\n",
       "      <td>1.560214</td>\n",
       "      <td>0.136213</td>\n",
       "      <td>0.058430</td>\n",
       "      <td>-0.207562</td>\n",
       "      <td>0.129703</td>\n",
       "      <td>0.631257</td>\n",
       "      <td>-0.073079</td>\n",
       "      <td>-0.072595</td>\n",
       "      <td>-0.046537</td>\n",
       "      <td>-1.095496</td>\n",
       "      <td>0.020650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-18.892884</td>\n",
       "      <td>1.320438</td>\n",
       "      <td>2.465213</td>\n",
       "      <td>-0.328190</td>\n",
       "      <td>-2.543895</td>\n",
       "      <td>0.728472</td>\n",
       "      <td>-1.207503</td>\n",
       "      <td>1.209443</td>\n",
       "      <td>0.543729</td>\n",
       "      <td>0.205445</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>-0.282376</td>\n",
       "      <td>-0.080303</td>\n",
       "      <td>0.704908</td>\n",
       "      <td>0.989034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.413480</td>\n",
       "      <td>-3.967846</td>\n",
       "      <td>-1.918874</td>\n",
       "      <td>0.249799</td>\n",
       "      <td>0.485784</td>\n",
       "      <td>0.726944</td>\n",
       "      <td>-0.507952</td>\n",
       "      <td>-0.138389</td>\n",
       "      <td>0.109414</td>\n",
       "      <td>0.208978</td>\n",
       "      <td>-0.092068</td>\n",
       "      <td>0.341340</td>\n",
       "      <td>-0.376660</td>\n",
       "      <td>-0.591348</td>\n",
       "      <td>0.472888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-10.221737</td>\n",
       "      <td>-0.903182</td>\n",
       "      <td>-1.343646</td>\n",
       "      <td>1.040087</td>\n",
       "      <td>2.489991</td>\n",
       "      <td>2.670366</td>\n",
       "      <td>-0.744474</td>\n",
       "      <td>2.248467</td>\n",
       "      <td>-0.269105</td>\n",
       "      <td>-0.410593</td>\n",
       "      <td>-1.574585</td>\n",
       "      <td>0.339117</td>\n",
       "      <td>-0.976271</td>\n",
       "      <td>0.889209</td>\n",
       "      <td>1.044498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.601570</td>\n",
       "      <td>0.028557</td>\n",
       "      <td>-10.087533</td>\n",
       "      <td>2.789941</td>\n",
       "      <td>-7.033029</td>\n",
       "      <td>-5.960131</td>\n",
       "      <td>0.690240</td>\n",
       "      <td>-2.786239</td>\n",
       "      <td>2.339409</td>\n",
       "      <td>5.522192</td>\n",
       "      <td>1.373146</td>\n",
       "      <td>0.145313</td>\n",
       "      <td>0.697186</td>\n",
       "      <td>0.479144</td>\n",
       "      <td>1.207805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1          2         3         4         5         6  \\\n",
       "0   1.121868 -4.745601  -3.924026  2.321226  1.560214  0.136213  0.058430   \n",
       "1 -18.892884  1.320438   2.465213 -0.328190 -2.543895  0.728472 -1.207503   \n",
       "2   8.413480 -3.967846  -1.918874  0.249799  0.485784  0.726944 -0.507952   \n",
       "3 -10.221737 -0.903182  -1.343646  1.040087  2.489991  2.670366 -0.744474   \n",
       "4  -1.601570  0.028557 -10.087533  2.789941 -7.033029 -5.960131  0.690240   \n",
       "\n",
       "          7         8         9        10        11        12        13  \\\n",
       "0 -0.207562  0.129703  0.631257 -0.073079 -0.072595 -0.046537 -1.095496   \n",
       "1  1.209443  0.543729  0.205445  0.680000 -0.282376 -0.080303  0.704908   \n",
       "2 -0.138389  0.109414  0.208978 -0.092068  0.341340 -0.376660 -0.591348   \n",
       "3  2.248467 -0.269105 -0.410593 -1.574585  0.339117 -0.976271  0.889209   \n",
       "4 -2.786239  2.339409  5.522192  1.373146  0.145313  0.697186  0.479144   \n",
       "\n",
       "         14  \n",
       "0  0.020650  \n",
       "1  0.989034  \n",
       "2  0.472888  \n",
       "3  1.044498  \n",
       "4  1.207805  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_3 = pd.read_csv(\"../common/albertom/train_test_val_split/X_val_pca.csv\", index_col=\"Unnamed: 0\")\n",
    "# df_data_3 = df_data_3.head(100)\n",
    "print(df_data_3.shape)\n",
    "df_data_3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 - Val labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3428, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>37382735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>16291467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>16215767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>39563885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>50610721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0         1\n",
       "0  0  37382735\n",
       "1  0  16291467\n",
       "2  0  16215767\n",
       "3  0  39563885\n",
       "4  0  50610721"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target_data_3 = pd.read_csv(\"../common/albertom/train_test_val_split/y_val.csv\", index_col=\"Unnamed: 0\")\n",
    "# df_target_data_3 = df_target_data_3.head(100)\n",
    "print(df_target_data_3.shape)\n",
    "df_target_data_3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Globals:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 - Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_folds = 3\n",
    "num_steps = 3001\n",
    "\n",
    "valid_size = df_data_3.shape[0]\n",
    "test_size = df_data_2.shape[0]\n",
    "batch_size = 128\n",
    "\n",
    "distinct_labels = len(df_target_data_1[\"0\"].unique())\n",
    "\n",
    "train_dataset = df_data_1.values\n",
    "val_dataset = df_data_3.values\n",
    "test_dataset = df_data_2.values\n",
    "\n",
    "split_labels = df_target_data_1[\"0\"].values\n",
    "train_labels = (np.arange(distinct_labels) == split_labels[:,None]).astype(np.float32)\n",
    "\n",
    "test_labels = df_target_data_2[\"0\"].values\n",
    "test_labels = (np.arange(distinct_labels) == test_labels[:,None]).astype(np.float32)\n",
    "\n",
    "val_labels = df_target_data_3[\"0\"].values\n",
    "val_labels = (np.arange(distinct_labels) == val_labels[:,None]).astype(np.float32)\n",
    "\n",
    "num_features = train_dataset.shape[1]\n",
    "num_examples = train_dataset.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 - Tensorflow graph: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data.\n",
    "    X = tf.placeholder(tf.float32, shape=(batch_size, num_features))\n",
    "    t = tf.placeholder(tf.int32, shape=(batch_size, distinct_labels))\n",
    "\n",
    "    L2_reg = tf.placeholder(tf.float32, shape=[])\n",
    "    learning_rate = tf.placeholder(tf.float32, shape=[])\n",
    "    \n",
    "    X_val = tf.constant(val_dataset, tf.float32)\n",
    "    X_test = tf.constant(test_dataset, tf.float32)\n",
    "\n",
    "    # Variables.\n",
    "    num_hidden1 = 10\n",
    "    num_hidden2 = 7\n",
    "    \n",
    "    W1 = tf.Variable(tf.truncated_normal([num_features, num_hidden1]) )\n",
    "    b1 = tf.Variable(tf.zeros([num_hidden1]))\n",
    "\n",
    "    W2 = tf.Variable(tf.truncated_normal([num_hidden1, distinct_labels]))\n",
    "    b2 = tf.Variable(tf.zeros([distinct_labels]))\n",
    "    \n",
    "    # Training.\n",
    "    h1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "    logits = tf.matmul(h1, W2) + b2\n",
    "    \n",
    "    # Loss NO reg.\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, t))\n",
    "    regularization = (tf.nn.l2_loss(W1) + tf.nn.l2_loss(b1) + tf.nn.l2_loss(W2) + tf.nn.l2_loss(b2))\n",
    "    loss = loss + L2_reg * regularization\n",
    "\n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "    # Predictions for training, validation.\n",
    "    train_predictions = tf.nn.softmax(logits)\n",
    "    val_predictions = tf.nn.softmax(tf.matmul(tf.nn.relu(tf.matmul(X_val, W1) + b1), W2) + b2)\n",
    "    test_predictions = tf.nn.softmax(tf.matmul(tf.nn.relu(tf.matmul(X_test, W1) + b1), W2) + b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 - Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Given a set of model parameters (learning rate, regularization penalty coefficient), find the optimal parameters with cross validation\n",
    "\n",
    "def holdout_validation(set_of_learning_rates, set_of_regs, X_train, y_train):\n",
    "    \n",
    "    # Get train-validation set stratified (keeps the same distribution) splitter\n",
    "    #skf = StratifiedKFold(n_splits=3)\n",
    "    set_of_params = [(x,y) for x in set_of_learning_rates for y in set_of_regs]\n",
    "    \n",
    "    #print(\"Number of folds: \" + str(n_folds))\n",
    "    print(\"Number of parameters combinations: \" + str(len(set_of_params)))\n",
    "    print(\"We will train \" + str(len(set_of_params)) + \" neural networks for this cv task.\")\n",
    "    \n",
    "    f1 = np.zeros(len(set_of_params))\n",
    "\n",
    "    for param_idx, param in enumerate(set_of_params):\n",
    "\n",
    "        print(str(param_idx) + \") Combination: [Parameters: \" +  str(param) + \" | Train model]\")\n",
    "        with tf.Session(graph=graph) as session:\n",
    "            tf.global_variables_initializer().run()\n",
    "                \n",
    "            for step in np.arange(num_steps):\n",
    "\n",
    "                offset = (step * batch_size) % (num_examples - batch_size)\n",
    "                X_batch = X_train[offset:(offset + batch_size), :]\n",
    "                t_batch = y_train[offset:(offset + batch_size)]\n",
    "                feed_dict = {\n",
    "                    X : X_batch,\n",
    "                    t : t_batch,\n",
    "                    L2_reg : param[1],\n",
    "                    learning_rate : param[0]\n",
    "                }\n",
    "                _, l, pred_batch = session.run( [optimizer, loss, train_predictions], feed_dict=feed_dict)\n",
    "                \n",
    "                if (step % 500 == 0):\n",
    "                    print(\"> Minibatch loss at step %d: %f\" % (step, l))\n",
    "                    print(\"> Training f1: %.1f%%\" % score(pred_batch, t_batch))\n",
    "                    print(\"> Validation f1: %.1f%%\" % score(val_predictions.eval(), val_labels))\n",
    "                \n",
    "            f1_cv = score(val_predictions.eval(), val_labels)\n",
    "            print(\"|> Final Validation f1: %.1f%%\" % f1_cv)\n",
    "            f1[param_idx] = f1[param_idx] + f1_cv\n",
    "\n",
    "    f1 = f1 / n_folds # Calculate average error\n",
    "    \n",
    "\n",
    "    print(\">>>>>> Best [learning rate - f1] = \", set_of_params[np.argmax(f1)][1])\n",
    "    print(\">>>>>> BEST [reg - f1] = \", set_of_params[np.argmax(f1)][0])\n",
    "\n",
    "    return set_of_params[np.argmax(f1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score(predictions, labels):\n",
    "    return f1_score(np.argmax(predictions, 1), np.argmax(labels, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Training: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 - Cross validation for optimal hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout validation on TRAINING-SET for [learning rate, L2_reg] ...\n",
      "Number of parameters combinations: 4\n",
      "We will train 4 neural networks for this cv task.\n",
      "0) Combination: [Parameters: (0.01, 0.01) | Train model]\n",
      "> Minibatch loss at step 0: 4.703604\n",
      "> Training f1: 0.4%\n",
      "> Validation f1: 0.3%\n",
      "> Minibatch loss at step 500: 1.082022\n",
      "> Training f1: 0.3%\n",
      "> Validation f1: 0.0%\n",
      "> Minibatch loss at step 1000: 0.945582\n",
      "> Training f1: 0.1%\n",
      "> Validation f1: 0.0%\n",
      "> Minibatch loss at step 1500: 0.941324\n",
      "> Training f1: 0.1%\n",
      "> Validation f1: 0.1%\n",
      "> Minibatch loss at step 2000: 0.924558\n",
      "> Training f1: 0.1%\n",
      "> Validation f1: 0.0%\n",
      "> Minibatch loss at step 2500: 0.870820\n",
      "> Training f1: 0.2%\n",
      "> Validation f1: 0.1%\n",
      "> Minibatch loss at step 3000: 0.851166\n",
      "> Training f1: 0.1%\n",
      "> Validation f1: 0.1%\n",
      "|> Final Validation f1: 0.1%\n",
      "1) Combination: [Parameters: (0.01, 0.02) | Train model]\n",
      "> Minibatch loss at step 0: 19.101748\n",
      "> Training f1: 0.4%\n",
      "> Validation f1: 0.3%\n",
      "> Minibatch loss at step 500: 1.559120\n",
      "> Training f1: 0.2%\n",
      "> Validation f1: 0.1%\n",
      "> Minibatch loss at step 1000: 1.316263\n",
      "> Training f1: 0.2%\n",
      "> Validation f1: 0.1%\n",
      "> Minibatch loss at step 1500: 1.203568\n",
      "> Training f1: 0.2%\n",
      "> Validation f1: 0.1%\n",
      "> Minibatch loss at step 2000: 1.120661\n",
      "> Training f1: 0.2%\n",
      "> Validation f1: 0.1%\n",
      "> Minibatch loss at step 2500: 0.983345\n",
      "> Training f1: 0.1%\n",
      "> Validation f1: 0.2%\n",
      "> Minibatch loss at step 3000: 0.928921\n",
      "> Training f1: 0.3%\n",
      "> Validation f1: 0.2%\n",
      "|> Final Validation f1: 0.2%\n",
      "2) Combination: [Parameters: (0.02, 0.01) | Train model]\n",
      "> Minibatch loss at step 0: 9.628156\n",
      "> Training f1: 0.2%\n",
      "> Validation f1: 0.1%\n",
      "> Minibatch loss at step 500: 0.906874\n",
      "> Training f1: 0.4%\n",
      "> Validation f1: 0.1%\n",
      "> Minibatch loss at step 1000: 0.746319\n",
      "> Training f1: 0.4%\n",
      "> Validation f1: 0.0%\n",
      "> Minibatch loss at step 1500: 0.734167\n",
      "> Training f1: 0.2%\n",
      "> Validation f1: 0.1%\n",
      "> Minibatch loss at step 2000: 0.743784\n",
      "> Training f1: 0.0%\n",
      "> Validation f1: 0.1%\n",
      "> Minibatch loss at step 2500: 0.676594\n",
      "> Training f1: 0.2%\n",
      "> Validation f1: 0.2%\n",
      "> Minibatch loss at step 3000: 0.652732\n",
      "> Training f1: 0.3%\n",
      "> Validation f1: 0.2%\n",
      "|> Final Validation f1: 0.2%\n",
      "3) Combination: [Parameters: (0.02, 0.02) | Train model]\n",
      "> Minibatch loss at step 0: 15.685896\n",
      "> Training f1: 0.4%\n",
      "> Validation f1: 0.2%\n",
      "> Minibatch loss at step 500: 1.317461\n",
      "> Training f1: 0.4%\n",
      "> Validation f1: 0.1%\n",
      "> Minibatch loss at step 1000: 0.984340\n",
      "> Training f1: 0.2%\n",
      "> Validation f1: 0.1%\n"
     ]
    }
   ],
   "source": [
    "set_of_learning_rates = np.arange(0.01, 0.03, step=0.01)\n",
    "set_of_L2_regs = np.arange(0.01, 0.03, step=0.01)\n",
    "\n",
    "print(\"Holdout validation on TRAINING-SET for [learning rate, L2_reg] ...\")\n",
    "\n",
    "best_params = cross_validation(set_of_learning_rates, set_of_L2_regs, train_dataset, train_labels)\n",
    "\n",
    "best_learning_rate = best_params[0]\n",
    "best_L2_reg = best_params[1]\n",
    "\n",
    "print(\"Best parameters: [\" + str(best_learning_rate) + \", \" + str(best_L2_reg) + \"] ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 - Prediction using optimal hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Prediction for TEST-SET using best parameters ...\")\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    \n",
    "    print(\"Combination: [Parameters: \" +  str(lr) + \", \" + str(L2_reg) + \" | Train model]\")\n",
    "    for step in np.arange(num_steps):\n",
    "                        \n",
    "        offset = (step * batch_size) % (num_examples - batch_size)\n",
    "        X_batch = train_dataset[offset:(offset + batch_size), :]\n",
    "        t_batch = train_labels[offset:(offset + batch_size), :]\n",
    "        feed_dict = {\n",
    "            X : X_batch,\n",
    "            t : t_batch,\n",
    "            L2_reg : best_L2_reg,\n",
    "            learning_rate : best_learning_rate\n",
    "        }\n",
    "        \n",
    "        _, l, pred_batch = session.run( [optimizer, loss, train_predictions], feed_dict=feed_dict)\n",
    "        if (step % 500 == 0):\n",
    "            print(\"> Minibatch loss at step %d: %f\" % (step, l))\n",
    "            print(\"> Training f1: %.1f%%\" % score(pred_batch, t_batch))\n",
    "            print(\"> Validation f1: %.1f%%\" % score(val_predictions.eval(), val_labels))\n",
    "                \n",
    "    f1_test = score(test_predictions.eval(), test_labels)\n",
    "    print(\"|> Test f1: %.1f%%\" % f1_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
